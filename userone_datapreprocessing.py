# -*- coding: utf-8 -*-
"""UserOne_dataPreprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A5vtSHAZLIFr5MNO_ta7RAk4Xyi8Kq3n
"""

'''
Created on 13-Apr-2020

@author: joel peter
'''

from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import io
import matplotlib.pyplot as plt
import numpy as np
import statistics
import seaborn as sns
import missingno as mno
from sklearn import linear_model
import datetime
# %matplotlib inline

user1_df = pd.read_csv(io.BytesIO(uploaded['u1.csv']), encoding = "ISO-8859-1")
trail_df = user1_df

"""**Remove Columns that aren't necessary. We won't be using this columns!! **"""

cols = ['lat', 'lon','song',' scan_glucose (mmol/L)','img01_id','img02_id','img03_id','img04_id','img05_id','img06_id','img07_id','img08_id','img09_id','img10_id','img11_id','img12_id','img13_id',
        'img14_id','img15_id','img16_id','img17_id','img18_id','img19_id','cam00_id','cam01_id','cam02_id','cam03_id','cam04_id','cam05_id','cam06_id','cam07_id',
        'cam08_id','cam09_id','cam10_id','cam11_id','cam12_id','cam13_id', 'cam14_id']

"""***Last 60 rows are null, can be removed***"""

user1_df.drop(cols, axis = 1, inplace = True)
user1_df.drop(user1_df.tail(60).index, inplace=True)

missing_column = 'heart_rate'
imputation_df = user1_df

"""Impute Value - Heart rate has a positive linear correlation with steps and parameters.
number_missing - get the index of rows with null heart rate
impute random heart_rate values taken in 'observered_values'
"""

def random_imputation(df, feature):
    number_missing = df[feature].isnull().sum()
    observed_values = df.loc[df[feature].notnull(), feature]
    df.loc[df[feature].isnull(), feature + '_imp'] = np.random.choice(observed_values, number_missing, replace = True)
    return df

imputation_df[missing_column + '_imp'] = imputation_df[missing_column]
imputation_df = random_imputation(imputation_df, missing_column)
imputation_df.rename(columns= {'historic_glucose (mmol/L)' : 'glucose'}, inplace = True)

"""Multi Linear Regression - To impute heart rate as calories and steps has positive linear relationship with heart_rate"""

deter_df = pd.DataFrame(columns = ["Det_" + 'heart_rate'])
missing_column_list = ['heart_rate'] 
deter_df["Det_" + 'heart_rate'] = imputation_df['heart_rate' + "_imp"]
parameters = ['calories', 'steps']
model = linear_model.LinearRegression()
model.fit(X = imputation_df[parameters], y = imputation_df['heart_rate_imp'])
deter_df.loc[imputation_df['heart_rate'].isnull(), 'Det_heart_rate'] = model.predict(imputation_df[parameters])[imputation_df['heart_rate'].isnull()]

"""Assign imputed column to the original dataframe"""

user1_df['heart_rate_imputed'] = deter_df['Det_heart_rate']

"""Remove the random impputed and column with null value"""

user1_df.drop(columns = [ 'heart_rate', 'heart_rate_imp'], inplace = True)

"""Take the local time(string) and convert it into date time object"""

for index, row in user1_df.iterrows():
  date_string = row['local_time']
  year = date_string[0:4]
  month = date_string[4:6]
  date = date_string[6:8]
  hour = date_string[9:11]
  minute = date_string[11:13]
  new_date = year + ' ' + month + ' ' + date + ' ' + hour + ':' + minute + ':00'
  user1_df.loc[index, 'new_row'] = new_date

user1_df.info()
#user1_df.head()

user1_df['new_row'] = user1_df['new_row'].astype(np.datetime64)
user1_df['date'] = pd.to_datetime(user1_df["new_row"].dt.strftime('%Y-%m-%d %H:%M:%S'))

new_df = user1_df.iloc[0:26270]
from google.colab import files
new_df.to_csv('user1_datapreprocessing.csv', date_format='%Y-%m-%d %H:%M:%S', index = False) 
files.download('user1_datapreprocessing.csv')