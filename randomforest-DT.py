# -*- coding: utf-8 -*-
"""RandomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XVgYo3X1SC5dRLuZCGaCCo40kP_t0yVq
"""

from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import io
import matplotlib.pyplot as plt
import numpy as np
import statistics
import seaborn as sns
import missingno as mno
from sklearn import linear_model
import datetime
# %matplotlib inline
from operator import itemgetter
from itertools import groupby
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor

Fea_Eng_df = pd.read_csv(io.BytesIO(uploaded['user1_cleaned_v2.0.csv']), encoding = "ISO-8859-1")

#dummy data - not required
Trump_df = Fea_Eng_df

# Null values appended in last row - no idea why it happens.. If its appended, remove the last row
'''
Fea_Eng_df = Fea_Eng_df.iloc[0:24888]
'''
Fea_Eng_df.info()
#Fea_Eng_df.head()

#impute null values
Fea_Eng_df.name.fillna('Unknown', inplace = True)
Fea_Eng_df.glucose.fillna('0.0', inplace = True)

Fea_Eng_df['refined_activity'] = Fea_Eng_df.activity2.astype(str).str.lower()

#New row for easier clasification

#Fea_Eng_df['refined_activity'] = Fea_Eng_df[['activity2']]

#Activity simplified

for index, row in Fea_Eng_df.iterrows():
  activity = row['activity2']
  if 'Travelling' in activity:
    Fea_Eng_df.loc['index' , 'refined_activity'] = 'Travelling'

Fea_Eng_df.describe()

Fea_Eng_df[Fea_Eng_df.dtypes[(Fea_Eng_df.dtypes=="float64")|(Fea_Eng_df.dtypes=="int64")]
                        .index.values].hist(figsize=[11,11])



'''Standardisation of values'''

scaled_features = Fea_Eng_df.copy()
col_names = ['steps', 'calories', 'glucose', 'distance', 'heart_rate_imputed']
features = scaled_features[col_names]
scaler = StandardScaler().fit(features.values)
features = scaler.transform(features.values)

Fea_Eng_df.head()

''' Replace the standardised feature back to dataframe'''

scaled_features[col_names] = features
scaled_features.head()



''' Drop these dumb useless feature - activity is repetitve'''
scaled_features.drop(columns=['minute_ID', 'activity'], inplace = True)

''' Change the dataset from string/object to categorical'''
scaled_features['name'] = scaled_features.name.astype(str).str.lower()
scaled_features['name'] = pd.Categorical(scaled_features['name'])
#scaled_features['activity2'] = pd.Categorical(scaled_features['activity2'])

scaled_features.info()

''' One hot encoding - as i said, just one line Borah'''

df_onehot = pd.get_dummies(scaled_features['name'], prefix = 'category')

scaled_features.info()

''' Do this if there is NAN in last row'''

scaled_features = scaled_features.iloc[0:24888]

''' append the one hot encodede values back to df'''

scaled_features = pd.concat([scaled_features, df_onehot], axis=1)

''' Remove columns to be fed into Y'''
scaled_features_oh = scaled_features.drop(columns=['glucose','activity2', 'date', 'name', 'refined_activity'])
#scaled_features_oh_em =  scaled_features_oh.copy()
#scaled_features_oh_em = scaled_features_oh.drop(columns=['glucose'])
#scaled_features_oh_em.info()

X = scaled_features_oh.values #Features
Y = scaled_features[['refined_activity']] #Label

#np.where(np.isnan(X))
#X.shape
#np.isnan(X)
#np.delete(X, 24888, 0)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)

clf = RandomForestClassifier(n_estimators=800, max_features= 3, max_depth= 150, min_samples_leaf=3, min_samples_split= 10)
clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)
from sklearn import metrics
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

feat_labels = scaled_features_oh.columns

import pandas as pd
feature_imp = pd.Series(clf.feature_importances_, feat_labels).sort_values(ascending=False)
feature_imp

from sklearn.model_selection import cross_val_score, validation_curve
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import f1_score
from sklearn.metrics import auc

rfc_cv_score = cross_val_score(clf, X, Y, cv=10)
print("=== Classification Report ===")
print(classification_report(y_test, y_pred))
print('\n')
print("=== All AUC Scores ===")
print(rfc_cv_score)
print('\n')
print("=== Mean AUC Score ===")
print("Mean AUC Score - Random Forest: ", rfc_cv_score.mean())

#rfc = RandomForestClassifier()
param_grid = {
    'bootstrap': [True],
    'max_depth': [90, 100, 110],
    'max_features': [2, 3],
    'min_samples_leaf': [ 4, 5],
    'min_samples_split': [8, 10, 12],
    'n_estimators': [500, 600, 700]
    
}

from sklearn.model_selection import GridSearchCV
#cv = GridSearchCV(rfc,parameters,cv=5)
#cv.fit(X_train,Y_train.values.ravel())
rf = RandomForestClassifier()
grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, 
                          cv = 3, n_jobs = -1, verbose = 2)

grid_search.fit(X_train, y_train)

grid_search.best_params_

best_grid = grid_search.best_estimator_
predictions = evaluate(best_grid, X_test, y_test)

print(type(rf))
print(type(best_grid))

def evaluate(model, test_features, Y_test):
    predictions = model.predict(test_features)
    print("Accuracy:",metrics.accuracy_score(Y_test, predictions))
    return predictions

from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report, confusion_matrix

rfc_cv_score = cross_val_score(clf, X, Y, cv=10)

from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
print("=== Classification Report ===")
print(classification_report(y_test, predictions))
print('\n')
print("=== All AUC Scores ===")
print(rfc_cv_score)
print('\n')
print("=== Mean AUC Score ===")
print("Mean AUC Score - Random Forest: ", rfc_cv_score.mean())

rfc_cv_score_rf = cross_val_score(rf, X, Y, cv=10)

print("=== Classification Report ===")
print(classification_report(y_test, predictions))
print('\n')
print("=== All AUC Scores ===")
print(rfc_cv_score_rf)
print('\n')
print("=== Mean AUC Score ===")
print("Mean AUC Score - Random Forest: ", rfc_cv_score_rf.mean())

scaled_features.head()

scaled_features_oh.head()

from google.colab import files

scaled_features.to_csv('scaled_features.csv')
files.download('scaled_features.csv')